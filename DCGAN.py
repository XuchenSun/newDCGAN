#s version

from tensorflow.keras.layers import Input

img_rows = 28 # define the size of image
img_cols = 28
channels = 1  # define channels 1 means white and black
img_shape = (img_rows, img_cols, channels)
latent_dim = 100
generator_input = Input(shape=(latent_dim,))


from tensorflow.keras.layers import Dense, Reshape

x = Dense(128 * 7 * 7, activation="relu",)(generator_input)
x = Reshape((7, 7, 128))(x)


from tensorflow.keras.layers import UpSampling2D

x = UpSampling2D()(x)


from tensorflow.keras.layers import Conv2D

x = Conv2D(128, kernel_size=3, padding='same')(x)


from tensorflow.keras.layers import BatchNormalization, Activation

x = BatchNormalization(momentum=0.8)(x)
x = Activation("relu")(x)


x = UpSampling2D()(x)
x = Conv2D(64, 3, padding='same')(x)
x = BatchNormalization(momentum=0.8)(x)
x = Activation("relu")(x)

x = Conv2D(channels, kernel_size=3, activation='tanh', padding='same')(x)


from tensorflow.keras.models import Model

generator = Model(generator_input, x)


generator.summary()


from tensorflow.keras.layers import LeakyReLU

discriminator_input = Input(shape=img_shape)
x = Conv2D(32, kernel_size=3, strides=2, padding="same")(discriminator_input)
x = LeakyReLU(alpha=0.2)(x)


from tensorflow.keras.layers import Dropout

x = Dropout(0.25)(x)



from tensorflow.keras.layers import Flatten, ZeroPadding2D

x = Conv2D(64, kernel_size=3, strides=2, padding="same")(x)
x = ZeroPadding2D(padding=((0, 1), (0, 1)))(x)
x = BatchNormalization(momentum=0.8)(x)
x = LeakyReLU(alpha=0.2)(x)
x = Dropout(0.25)(x)
x = Conv2D(128, kernel_size=3, strides=2, padding="same")(x)
x = BatchNormalization(momentum=0.8)(x)
x = LeakyReLU(alpha=0.2)(x)
x = Dropout(0.25)(x)
x = Conv2D(256, kernel_size=3, strides=1, padding="same")(x)
x = BatchNormalization(momentum=0.8)(x)
x = LeakyReLU(alpha=0.2)(x)
x = Dropout(0.25)(x)
x = Flatten()(x)
x = Dense(1, activation='sigmoid')(x)


discriminator = Model(discriminator_input, x)


discriminator.summary()


from tensorflow.keras.optimizers import Adam

# Initialize Adam
optimizer = Adam(0.0002, 0.5)
# Compile the model
discriminator.compile(loss='binary_crossentropy',
                      optimizer=optimizer,
                      metrics=['accuracy'])


discriminator.trainable = False


gan_input = Input(shape=(latent_dim,))
gan_output = discriminator(generator(gan_input))

gan = Model(gan_input, gan_output)
gan.compile(optimizer=optimizer, loss='binary_crossentropy')

import numpy as np
from tensorflow.keras.datasets import mnist

#load MNIST handwriting database
(X_train, _), (_, _) = mnist.load_data()
# Data standardization, zoom to [- 1,1], and use the reshape method to increase a dimension to represent the number of channels
X_train = X_train.reshape((X_train.shape[0],)+img_shape)/127.5-1.
# Set the number of training cycles epochs to 4000, and input the number of images in each round batch_ The size is 128
epochs = 4000
batch_size = 128
# make label
valid = np.ones((batch_size, 1))
fake = np.zeros((batch_size, 1))

valid += 0.01 * np.random.random(valid.shape)
fake += 0.01 * np.random.random(fake.shape)


import numpy as np
import matplotlib.pylab as plt
from tensorflow.keras.preprocessing import image



for epoch in range(epochs):
    # ---------------------
    #  train discriminator
    # ---------------------
    # Through the randomly selected sequence IDX, the number of real images IMGs in one round is randomly selected
    idx = np.random.randint(0, X_train.shape[0], batch_size)
    imgs = X_train[idx]
    # In the potential space, random points are randomly selected to form random noise
    noise = np.random.normal(0, 1, (batch_size, latent_dim))
    # Using these random noises, Gen is generated by generator_ IMGs composite image
    gen_imgs = generator.predict(noise)
    # The real image and synthetic image are put into the discriminator for training
    # get two kinds of value: d_loss_real 和 d_loss_fake
    d_loss_real = discriminator.train_on_batch(imgs, valid) # the number of loss in discriminator
    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)# the number of fake in discriminator
    # the final loss value of discriminator is the average of d_loss_real and d_loss_fake
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
    # ---------------------
    #  train generator
    # ---------------------
    # Random extraction of new points in potential space
    noise = np.random.normal(0, 1, (batch_size, latent_dim))

    # train generator by GUN model
    g_loss = gan.train_on_batch(noise, valid)
    # every 50 epoch
    if epoch % 50 == 0:# every 50 epoch

        # print the loss of discriminator and generator and accuracy
        print("%d [D loss: %f] [G loss: %f]" %
              (epoch, d_loss[0], g_loss))

        # zoom pix of image from [-1,1] to [0，1]
        gen_imgs = 0.5*gen_imgs+0.5


        # use plt.subplots to creat pictures，display  5×5 images
        _, axs = plt.subplots(5, 5)
        # cnt shows the number of images
        cnt = 0
        # use imshow function to transfer gen_imgs from array to image
        for i in range(5):
            for j in range(5):
                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')
                axs[i, j].axis('off')
                cnt += 1
        # use plt.show to show the image
        plt.show()
        # in loop，after showing the image, I need to use plt.close to close the image
        # If I don't do that, next time the model will show the previous image.
        plt.close()